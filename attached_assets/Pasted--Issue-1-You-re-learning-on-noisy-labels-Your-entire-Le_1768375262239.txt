ðŸ”´ Issue #1: Youâ€™re learning on noisy labels

Your entire LearningEngine assumes:

HourlySnapshot.unique_drivers â‰ˆ real supply


But upstream:

dedup still occasionally splits one real driver into 2

grid overlap causes short-term inflation

freeway movement creates transient spikes

So your learning model:

builds patterns on unstable numbers

then anomalies explode

then decisions contradict each other

âš ï¸ Result

z-scores go crazy

correlations flip sign

movement suggestions oscillate

ðŸ”´ Issue #2: Statistical assumptions are violated

You are using Gaussian assumptions everywhere:

z_score = (current - expected) / std


But Uber supply:

is NOT normally distributed

has fat tails

has regime changes (events, weather, surge)

âš ï¸ Result

std_dev == 0 â†’ divide-by-zero logic

anomaly false positives

confidence collapses

ðŸ”´ Issue #3: You mix learning, evaluation, decision-making in one engine

Right now:

same engine writes data

reads data

detects anomalies

makes movement decisions

validates predictions

This causes feedback loops:

bad prediction â†’ bad validation â†’ worse confidence â†’ worse decision

2ï¸âƒ£ Concrete fixes (do THESE, not refactors)
âœ… Fix #1: Stop learning from raw counts â€” use smoothed supply

Before anything enters LearningEngine, create:

effective_supply = median(last 3 cycles)


or

effective_supply = EWMA(alpha=0.3)


Replace:

snap.unique_drivers


with:

snap.effective_drivers


This alone will reduce breakage by ~60%.

âœ… Fix #2: Replace z-score anomaly detection (CRITICAL)

Instead of:

z = (current - mean) / std


Use percent deviation with caps:

deviation = (current - expected) / max(expected, 1)


Then:

is_anomaly = abs(deviation) > 0.35


Why?

robust to skew

works with low counts

stable in nightlife patterns

ðŸ‘‰ Keep std_dev for reporting only, not logic.

âœ… Fix #3: Require temporal confirmation for anomalies

Right now:

one bad hour â†’ anomaly

Change to:

anomaly = deviation persists â‰¥ 2 consecutive slots

Implementation:

store last N deviations per zone

only flag anomaly if 2 of last 3 exceed threshold

âœ… Fix #4: Freeze learning when confidence is low

Add this guard everywhere:

if pattern.confidence < 0.5:
    skip learning / prediction


Do NOT:

generate predictions

detect anomalies

suggest movement

Low-confidence data poisons everything downstream.

3ï¸âƒ£ Specific problems in your current code

Iâ€™ll point out exact break points.

âŒ Problem: run_hourly_analysis()

You aggregate:

data['fingerprints'].add(obs.fingerprint_id)


But:

fingerprint IDs are probabilistic

dedup may change IDs over time

âœ… Fix

Track:

high_confidence_fingerprints only (confidence â‰¥ 0.7)

âŒ Problem: run_daily_analysis()
std_drivers = sqrt(variance)


But:

many hours have flat supply

variance becomes 0

later z-score logic breaks

âœ… Fix

Clamp:

std_drivers = max(std_drivers, avg_drivers * 0.15)

âŒ Problem: Correlation learning

You do:

if abs(correlation) > 0.5


This is way too low for noisy city data.

âœ… Fix

Raise to:

abs(correlation) > 0.7 AND sample_count â‰¥ 10


Otherwise you learn ghosts.

âŒ Problem: Movement recommendation logic

You require:

from_surplus AND to_shortage


But supply is relative, not absolute.

âœ… Fix

Use ratio, not absolute:

from_ratio = from_current / expected
to_ratio   = to_current / expected


Recommend move if:

from_ratio > 1.25 AND to_ratio < 0.8


This matches how Uber actually behaves.